{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: right;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")\n",
    "\n",
    "# system ----\n",
    "import os\n",
    "import sys\n",
    "import matplotlib\n",
    "import h5py\n",
    "import numpy as np\n",
    "from scipy import integrate\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.legend_handler import HandlerBase\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    " \n",
    "# !!! you will have to edit this to your local computer\n",
    "\n",
    "# local ----\n",
    "localPath = os.path.expanduser(\"~/\")\n",
    "projPath = os.path.expanduser(localPath+\"_projects/researchproject_014/\")\n",
    "sys.path.append(projPath+\"modules\")\n",
    "import plot_parameters \n",
    "\n",
    "# !!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Data set\n",
    "\n",
    "This example dataset consists of the PHAT-ELVIS suite of Milky-way size halos with analytical potential profiles (i.e. the galactic bulge and galactic disk) analogous to the Milky Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosmology\n",
    "params = {\n",
    "    'h0'     : 0.6751,\n",
    "    'omegaM' : 0.3121,\n",
    "    'omegaL' : 0.6879,\n",
    "    'omegaB' : 0.0000,\n",
    "    'omegaR' : 0.0000,\n",
    "    'boxsize': 1,\n",
    "    }\n",
    "h0=params['h0']\n",
    "\n",
    "# ---- load in dataset\n",
    "hid=str(988) # specific main halo simulation\n",
    "# rockstar catalog\n",
    "cat=np.genfromtxt(projPath+'/outputs/pelvis/halo_catalog_disk_'+hid+'.csv',\n",
    "                  skip_header=1,delimiter=',')\n",
    "# merger tree catalog\n",
    "tree=np.genfromtxt(projPath+'/outputs/pelvis/main_branches_disk_'+hid+'_trimmed.csv',\n",
    "                   skip_header=1,delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nomenclature\n",
    "\n",
    "The target halo of this simulations are Milky Way-mass dark matter halos simulated with a growing potential disk and potential bulge (see https://arxiv.org/abs/1811.12413). The target halo, which we will call the **host halo** is a *isolated* dark matter halo that was simulated. A host halo is typically defined to be a halo that did not form nor currently reside in a larger halo. \n",
    "\n",
    "For the contents underneath, check out these slides from http://www.astro.yale.edu/vdbosch/astro610_lecture11.pdf.\n",
    "\n",
    "### Dark Matter Halos\n",
    "\n",
    "Dark matter halos are typically defined to be objects that have a density that starkingly contrasts from the background density of the universe, $\\rho_{\\rm bg}$. For example, the background can be defined by the *critical density*, $\\rho_{\\rm crit}$, or the *mean matter density*, $\\rho_{\\rm m} := \\Omega_{\\rm m}\\rho_{\\rm crit}$. Typically, halos are defined by the contrast via a overdensity parameter, $\\Delta$, giving the halo mass (and radius) as\n",
    "\n",
    "\\begin{align}\n",
    "M_{\\Delta} := \\frac{4\\pi R_{\\Delta}^{3}}{3} (\\Delta \\times \\rho_{\\rm bg}) \n",
    "\\, ,\n",
    "\\end{align}\n",
    "\n",
    "Note that $R_{\\Delta}$ is *not a physical boundary* of a dark matter halo.\n",
    "\n",
    "Halos are defined by many definitions overdensity througout the literature, so you need to thoroughly read in methodology sections of *each paper* to see how they are defined. The most popular definition we will roll with is the classic *virial overdensity*, $\\Delta_{\\rm vir}$, with the critical density of the universe, $\\rho_{\\rm crit}(z)$, which are both redshift evolving. Its analytical form is given in https://arxiv.org/abs/astro-ph/9710107. Thus we have dark matter halos defined as\n",
    "\n",
    "\\begin{align}\n",
    "    M_{\\rm vir} := \\frac{4\\pi R_{\\rm vir}^{3}}{3} \\Delta_{\\rm vir}(z)\\, \\rho_{\\rm crit}(z) \n",
    "    \\, .\n",
    "\\end{align}\n",
    "\n",
    "To model the *physical growth*, instead of the pseudo-evolving growth (from $\\Delta_{\\rm vir}$ and $\\rho_{\\rm bg}$), of dark matter halos, we can parameterize the profile by the maximum circular velocity,\n",
    "\\begin{align}\n",
    "    V_{\\rm max} := \\mathrm{max}\\left[ \\sqrt{\\frac{GM(<R)}{R}} \\right]\n",
    "    \\, ,\n",
    "\\end{align}\n",
    "and the radius, $R_{\\rm max}$, at which $V_{\\rm max}$ is obtained. \n",
    "\n",
    "### Subhalos and Satellites\n",
    "\n",
    "**Subhalos** (or substructure) are typically defined to be halos that formed inside and/or are located inside a much larger halo. The satellites for the Milky Way are located inside $R_{\\rm vir}(z=0)$ at present day. Satellites are typically defined as subhalos orbiting the Milky Way halo, i.e., subhalos *bound* to the potential of Milky Way. We will focus on halos presently found inside the Milky Way halo.\n",
    "\n",
    "As a side discussion, halos found outside a host are typically referred to as *halos in the field* or the *halos of the background*. \n",
    "\n",
    "\n",
    "### Structure of CDM Halos\n",
    "\n",
    "A classic result from pure CDM simulations are that a variety of halo mass ranges are characterized by a single dark matter profile, i.e., a *universal* *NFW profile*:\n",
    "\n",
    "\\begin{align}\n",
    "    \\rho(r) = \\frac{\\rho_{s}}{(r/r_{s})(1+r/r_{s})^{2}}\n",
    "    \\, ,\n",
    "\\end{align}\n",
    "\n",
    "where $\\rho_{s}:=\\rho(r_{s})$ and $r_{s}$ are, respectively, the scale density and scale radius and can be thought as free parameters. \n",
    "\n",
    "A way of connecting how dense these objects are inside $r_{s}$, *relative* to the size of the halo $R_{\\rm vir}$, is called the **concentration** of the:\n",
    "\n",
    "\\begin{align}\n",
    "    c_{\\rm vir} = \\frac{r_{s}}{R_{\\rm vir}}\n",
    "    \\, .\n",
    "\\end{align}\n",
    "\n",
    "Once you read through the vast literature, papers typically studied the concentration-mass relation of the halos in the background. However, note that concentration for *subhalos* follow a different trend, since their are dynamical effects of the host halo background \"stripping\" the subhalo mass profile. \n",
    "\n",
    "Typically for NFW, one can relate the $V_{\\rm max}$ and $R_{\\rm max}$ to the concentration. For example, $r_{s} \\simeq 2.163\\, R_{\\rm max}$. Another way of definining the concentration is with $V_{\\rm max}/V_{\\rm vir}$, where $V_{\\rm vir} := GM_{\\rm vir}/R_{\\rm vir}$. Ways of defining the concentration will be more apparent when you start to think about the concentration of field halos to substructure.\n",
    "\n",
    "Everything except these structure quantities are defined in the `Cosmology` class below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cosmology(object):\n",
    "\n",
    "    def __init__(self,h0=0.704,omegaM=0.2726,omegaL=0.7274,omegaB=0.0456,omegaR=0,boxsize=106.5,**kwargs):\n",
    "        self.h0 = float(h0)\n",
    "        self.omegaM = float(omegaM)\n",
    "        self.omegaL = float(omegaL)\n",
    "        self.omegaB = float(omegaB)\n",
    "        self.omegaR = float(omegaR)\n",
    "        self.boxsize = float(boxsize)\n",
    "\n",
    "    def scale_factor(self, z):\n",
    "        return 1./(z + 1.)\n",
    "\n",
    "    def H(self, z):\n",
    "        H0 = 100 * self.h0 # km/s/Mpc\n",
    "        aa = self.scale_factor(z)\n",
    "        omegaMz = (self.omegaM + self.omegaB) * np.power(1.+z, 3)\n",
    "        omegaLz = self.omegaL\n",
    "        omegaRz = self.omegaR * np.power(1.+z,4)\n",
    "        omegaKz = (1. - self.omegaM - self.omegaL - self.omegaR) * np.power(1.+z,2)\n",
    "        return H0 * np.sqrt(omegaMz + omegaLz) # km/s/Mpc\n",
    " \n",
    "    def delta_vir(self, z): # The virial overdensity from Bryan & Norman (1998)\n",
    "        a = self.scale_factor(z)\n",
    "        Omega = self.omegaM*np.power(1.+z,3) / (self.omegaM*np.power(1.+z,3) + self.omegaL)\n",
    "        x = Omega - 1.\n",
    "        return (18.*np.pi**2. + 82.*x - 39.*x**2.)\n",
    " \n",
    "    def rho_crit(self, z):\n",
    "        a = self.scale_factor(z)\n",
    "        H = self.H(z)/3.09e+19 # 1/s\n",
    "        G = 6.67408e-11/1000/1000/1000 # Converson of m^3/kg/s^2 --> km^3/kg/s^2\n",
    "        return 3. * H**2. /(8*np.pi*G) # kg/km^3\n",
    " \n",
    "    def virial_radius(self, z, Mvir):\n",
    "        Mvir = np.float64(Mvir) * 1.989e+30 # Conversion of Msol --> kg\n",
    "        return np.power( 3. * Mvir/self.delta_vir(z)/self.rho_crit(z)/(4.*np.pi), 1./3) * 3.24078e-17 # km --> kpc\n",
    "\n",
    "    def virial_velocity(self, z, Mvir):\n",
    "        G = 6.67408e-11/1000/1000/1000 # m^3/kg/s^2 --> km^3/kg/s^2\n",
    "        radius = self.virial_radius(z, Mvir) * 3.086e+16 # kpc --> km\n",
    "        Mvir = float(Mvir) * 1.989e+30 # Msol --> kg\n",
    "        return np.sqrt(G*Mvir/radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Halo catalog @ $z=0$\n",
    "\n",
    "What I am doing here is loading all of the halo properties from the $z=0$ catalogs and making my selections for the subhalo populations so that we can follow their history through the merger trees. \n",
    "\n",
    "First, we load all of the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z=0 halo catalog\n",
    "# (0)host_id, (1)tree, (2)id, \n",
    "# (3)mvir, (4)rs, (5)rvir, (6)vmax,\n",
    "# (7)vx, (8)vy, (9)vz, (10)x, (11)y, (12)z,\n",
    "# vpeak, scale_vpeak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#... load data\n",
    "\n",
    "# The main branch these halos belong to...\n",
    "treeid=cat[:,1].astype(int); #print(treeid)\n",
    "\n",
    "# halo mass and halo radius\n",
    "mvir=cat[:,3]/h0 # Msol \n",
    "rvir=cat[:,5]/h0 # ckpc\n",
    "\n",
    "# Positions are saved in \"comoving\" units and are (from historical purposes) normalized by h0.\n",
    "pos=np.zeros((mvir.shape[0],3)) # 3D cartesian coordinates\n",
    "pos[:,0]=cat[:,10]; pos[:,1]=cat[:,11]; pos[:,2]=cat[:,12];\n",
    "pos*=1e3/h0 # ckpc\n",
    "# Since we are only loading the z=0 data, you wont have to worry about converting to physical units here.\n",
    "\n",
    "# Velocities are saved in physical units called \"peculiar velocities\"\n",
    "vel=np.zeros((mvir.shape[0],3)) # 3D cartesian velocities\n",
    "vel[:,0]=cat[:,7]; vel[:,1]=cat[:,8]; vel[:,2]=cat[:,9]; # km/s\n",
    "\n",
    "vmax=cat[:,6]; vpeak=cat[:,13]; vp_scale=cat[:,14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We that, we make our halo selection. First, we find the host MW halo in the simulations, which should be the most massive dark matter halo. We will only select halos within $R_{\\rm vir}$ at $z=0$ and only look at \"numerically resolved\" dark matter subhalos. These will be subhalos with $M_{\\rm vir} \\gtrsim 7\\times10^{7}\\ M_{\\odot}$ and $V_{\\rm max} > 4.5\\ \\rm\\ km\\ s^{-1}$. I wouldn't worry about this cutoff right now; we can follow up on this in a later discussion. \n",
    "\n",
    "All we want here is the tree root id of the subhalos for the merger tree catalog, which we define as `nstree_id_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find main halo, i.e. the most massive halo at z=0 in this case\n",
    "w=np.where(mvir==max(mvir))[0]\n",
    "htreeid=treeid[w][0]\n",
    "hmass=mvir[w][0]; hrvir=rvir[w][0]\n",
    "hpos=pos[w][0]; hvel=vel[w][0]\n",
    "\n",
    "# satellites @ z=0 (everything resolved inside rvir)\n",
    "streeid=np.delete(treeid,w,0) # all i'm doing is removing the main halo from the previous dataset\n",
    "smass=np.delete(mvir,w,0); svmax=np.delete(vmax,w,0);\n",
    "streeid=np.delete(treeid,w,0)\n",
    "spos=np.delete(pos,w,0); svel=np.delete(vel,w,0)\n",
    "vpeak=np.delete(vpeak,w,0); vp_scale=np.delete(vp_scale,w,0)\n",
    "\n",
    "sep=hpos-spos; rsep=np.sqrt(sep[:,0]**2 + sep[:,1]**2 + sep[:,2]**2)\n",
    "mask=np.where((rsep/hrvir<1.)&(svmax>4.5)&(smass>7e7))[0]; #print(mask.shape[0])\n",
    "nstree_id_=streeid[mask] # this allow us to use these results with the merger tree data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamical Equations\n",
    "\n",
    "The (physical) **relative position** of the satellite at some redshift in the galactocentric frame (GC) of the host is \n",
    "\n",
    "\\begin{align}\n",
    "    \\boldsymbol{r}_{\\rm rel}(z) := \\boldsymbol{r}_{\\rm host}(z) - \\boldsymbol{r}_{\\rm sat}(z)\\, ,\n",
    "\\end{align}\n",
    "\n",
    "where $\\boldsymbol{r}(z) := a(z)\\boldsymbol{x}(z)$ with $\\boldsymbol{x}$ denoted as the **comoving position** inside the cosmological box and $a(z)$ is the **scale factor**. Typically, the halo catalogs (like the ones used here) save the halo positions in comoving coordinates and must be converted to physical when appropriate. If you are wanting to find the pericenter of a satellite (the shortest GC distance along its orbit), you can say $r_{\\rm peri} = \\mathrm{min}|\\boldsymbol{r}_{\\rm rel}(z)|$.\n",
    "\n",
    "Similarly, the relative **peculiar velocity** in the GC frame follows\n",
    "\n",
    "\\begin{align}\n",
    "    \\boldsymbol{v}_{\\rm rel,pec}(z) := \\boldsymbol{v}_{\\rm host}(z) - \\boldsymbol{v}_{\\rm sat}(z)\\, .\n",
    "\\end{align}\n",
    "\n",
    "The halo catalogs always gives the halo velocity in terms of the peculiar (i.e., physical) velocity. The **total** (physical) velocity considered for our analysis accounts the Hubble flow:\n",
    "\n",
    "\\begin{align}\n",
    "    \\boldsymbol{v}_{\\rm rel}(z)= H(z)\\boldsymbol{r}_{\\rm rel}(z) + \\underbrace{a(z)\\dot{\\boldsymbol{x}}_{\\rm rel}(z)}_{\\boldsymbol{v}_{\\rm rel,pec}}\\, ,\n",
    "\\end{align}\n",
    "\n",
    "where $H(z) := \\dot{a}/a$. Motions of the satellite halos can be decomposed into simplified dynamical information, one being the **radial velocity**:\n",
    "\n",
    "\\begin{align}\n",
    "    v_{\\rm rad} := \\frac{\\boldsymbol{r}_{\\rm rel}\\cdot\\boldsymbol{v}_{\\rm rel}}{|\\boldsymbol{r}_{\\rm rel}|}\\, ,\n",
    "\\end{align}\n",
    "\n",
    "while the **tangential velocity** is just $v_{\\rm tan}^{2} = v_{\\rm rel}^{2} -v_{\\rm rad}^{2} $. \n",
    "\n",
    "\n",
    "I saved of this information within the `Dynamics` class in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dynamics(Cosmology):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Dynamics, self).__init__(**kwargs)\n",
    "\n",
    "    def periodic(self,z,sep): # not used here\n",
    "        a = self.scale_factor(z)\n",
    "        boxl = self.boxsize*a*1000 # phyical kpc\n",
    "        sep[sep < -boxl/2] += boxl\n",
    "        sep[sep > boxl/2] -= boxl\n",
    "        return sep\n",
    "\n",
    "    def distance(self,z,hostpos,satpos):\n",
    "        results={}\n",
    "        #a = self.scale_factor(z)\n",
    "        sep_vec=np.zeros(satpos.shape) # physical kpc\n",
    "        sep_vec[:,0]=(hostpos[:,0]-satpos[:,0])\n",
    "        sep_vec[:,1]=(hostpos[:,1]-satpos[:,1])\n",
    "        sep_vec[:,2]=(hostpos[:,2]-satpos[:,2])\n",
    "        sep_mag=np.sqrt(np.power(sep_vec[:,0],2)+np.power(sep_vec[:,1],2)+np.power(sep_vec[:,2],2))\n",
    "        results['relative.distance:vector']=sep_vec\n",
    "        results['relative.distance:magnitude']=sep_mag\n",
    "        return results\n",
    "\n",
    "    def total_velocity(self, z, hostvel, satvel, hostpos, satpos):\n",
    "        results={}\n",
    "        #a = self.scale_factor(z)\n",
    "        H=self.H(z)*1e-3 # km/s/kpc\n",
    "\n",
    "        dist_dict=self.distance(z,hostpos,satpos) # physical kpc\n",
    "        reldis_vec=dist_dict['relative.distance:vector']\n",
    "        reldis_mag=dist_dict['relative.distance:magnitude']\n",
    "\n",
    "        relvel_vec=np.zeros(satvel.shape) # km/s\n",
    "        relvel_vec[:,0]=(hostvel[:,0]-satvel[:,0])\n",
    "        relvel_vec[:,1]=(hostvel[:,1]-satvel[:,1])\n",
    "        relvel_vec[:,2]=(hostvel[:,2]-satvel[:,2])\n",
    "\n",
    "        hubble=np.zeros(reldis_vec.shape)\n",
    "        for i in range(reldis_vec.shape[0]):\n",
    "            hubble[i]+=reldis_vec[i]*H[i]\n",
    "        totvel_vec=hubble+relvel_vec # km/s\n",
    "        #totvel_vec=relvel_vec # km/s\n",
    "        totvel_mag=np.sqrt(np.power(totvel_vec[:,0],2)+np.power(totvel_vec[:,1],2)+np.power(totvel_vec[:,2],2))\n",
    "\n",
    "        results['total.velocity:vector']=totvel_vec\n",
    "        results['total.velocity:magnitude']=totvel_mag\n",
    "        return results\n",
    "\n",
    "    def radial_velocity(self, z, hostvel, satvel, hostpos, satpos):\n",
    "        H=self.H(z)/1000. # km/s/kpc\n",
    "        #a=self.scale_factor(z)\n",
    "\n",
    "        dist_dict=self.distance(z,hostpos,satpos) # physical kpc\n",
    "        reldis_vec=dist_dict['relative.distance:vector']\n",
    "        reldis_mag=dist_dict['relative.distance:magnitude']\n",
    "        totvel_dict=self.total_velocity(z,hostvel,satvel,hostpos,satpos) # km/s\n",
    "        #relvel_vec=hostvel-satvel\n",
    "        totvel_vec=totvel_dict['total.velocity:vector']\n",
    "\n",
    "        numer=totvel_vec[:,0]*reldis_vec[:,0]+totvel_vec[:,1]*reldis_vec[:,1]+totvel_vec[:,2]*reldis_vec[:,2]\n",
    "        return numer/reldis_mag\n",
    "\n",
    "    def tangential_velocity(self, z, hostvel, satvel, hostpos, satpos):\n",
    "        rad_vel=self.radial_velocity(z, hostvel, satvel, hostpos, satpos)\n",
    "        tot_vel=self.total_velocity(z, hostvel, satvel, hostpos, satpos)['total.velocity:magnitude']\n",
    "        return np.sqrt(np.power(tot_vel,2) - np.power(rad_vel,2))\n",
    "\n",
    "    def space_velocity(self, z, hostvel, satvel, hostpos, satpos):\n",
    "        rad_vel=self.radial_velocity(z,hostvel,satvel,hostpos,satpos)\n",
    "        tot_vel=self.total_velocity(z,hostvel,satvel,hostpos,satpos)['total.velocity:magnitude']\n",
    "        return tot_vel*np.sign(rad_vel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merger tree data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmerger tree info:\\n        (0) host_id : simulation number. Host mass decreases as this increases\\n        (1) tree : tree number (main branch) this halo belongs to\\n        (2) scale : scale factor of the halo properties\\n        (3) id : specific halo number (unique within `host_id` groups)\\n        (4) pid : ID of the parent halo (-1 if not a subhalo)\\n        (5) upids : ID of the uppermost halo (-1 if not a sub-subhalo, equals `pid` if subhalo)\\n        (6) phantom : Nonzero if the halo is not found by Rockstar, but used to link snapshots\\n        (7) mass : mass of the subhalo (Msun/h)\\n        (8) rvir : virial radius (kpc/h comoving)\\n        (9) rs : scale radius of best fit NFW profile as determined by Rockstar (kpc/h comoving)\\n        (10)vmax : maximum circular velocity (km/s)\\n        (11)x : x coordinate of center (Mpc/h comoving)\\n        (12)y : y coordinate of center (Mpc/h comoving)\\n        (13)z : z coordinate of center (Mpc/h comoving)\\n        (14)vx : x bulk velocity (km/s)\\n        (15)vy : y bulk velocity (km/s)\\n        (16)vz : z bulk velocity (km/s)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "merger tree info:\n",
    "        (0) host_id : simulation number. Host mass decreases as this increases\n",
    "        (1) tree : tree number (main branch) this halo belongs to\n",
    "        (2) scale : scale factor of the halo properties\n",
    "        (3) id : specific halo number (unique within `host_id` groups)\n",
    "        (4) pid : ID of the parent halo (-1 if not a subhalo)\n",
    "        (5) upids : ID of the uppermost halo (-1 if not a sub-subhalo, equals `pid` if subhalo)\n",
    "        (6) phantom : Nonzero if the halo is not found by Rockstar, but used to link snapshots\n",
    "        (7) mass : mass of the subhalo (Msun/h)\n",
    "        (8) rvir : virial radius (kpc/h comoving)\n",
    "        (9) rs : scale radius of best fit NFW profile as determined by Rockstar (kpc/h comoving)\n",
    "        (10)vmax : maximum circular velocity (km/s)\n",
    "        (11)x : x coordinate of center (Mpc/h comoving)\n",
    "        (12)y : y coordinate of center (Mpc/h comoving)\n",
    "        (13)z : z coordinate of center (Mpc/h comoving)\n",
    "        (14)vx : x bulk velocity (km/s)\n",
    "        (15)vy : y bulk velocity (km/s)\n",
    "        (16)vz : z bulk velocity (km/s)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_ids=tree[:,1]; scale=tree[:,2]; redshift=1./scale - 1.\n",
    "tmvir=tree[:,7]/h0; # Msol\n",
    "trvir=tree[:,8]/h0 # ckpc\n",
    "tvmax=tree[:,10]; # ckpc\n",
    "trmax=tree[:,9]*2.163/h0 # ckpc\n",
    "xpos=tree[:,11]; ypos=tree[:,12]; zpos=tree[:,13]\n",
    "xvel=tree[:,14]; yvel=tree[:,15]; zvel=tree[:,16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the **main halo** tree to a dictionary called `host_tree`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_tree={}\n",
    "wh=np.where(tree_ids==htreeid)[0]\n",
    "host_tree['virial.mass']=tmvir[wh] # Msol\n",
    "host_tree['scale']=scale[wh]; host_tree['redshift']=redshift[wh]\n",
    "host_tree['virial.radius']= host_tree['scale']*trvir[wh]/h0 # physical kpc\n",
    "\n",
    "host_tree['position']=np.zeros((host_tree['scale'].shape[0],3)) # physical kpc\n",
    "host_tree['position'][:,0]=host_tree['scale']*xpos[wh]*1e3/h0\n",
    "host_tree['position'][:,1]=host_tree['scale']*ypos[wh]*1e3/h0\n",
    "host_tree['position'][:,2]=host_tree['scale']*zpos[wh]*1e3/h0\n",
    "\n",
    "host_tree['velocity']=np.zeros((host_tree['scale'].shape[0],3)) # peculiar km/s\n",
    "host_tree['velocity'][:,0]=xvel[wh]; host_tree['velocity'][:,1]=yvel[wh]; host_tree['velocity'][:,2]=zvel[wh]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to the **satellite halo** data that we have saved in `nstree_id_`. We are going to update it by swifting out objects called \"orphan\" halos. These are halos that sometimes appear out of nowhere from the tree and fast flybys for the host. Objects like these are not typical in zoom-in simulations, but are apparent in large-box cosmologcial simulations. \n",
    "\n",
    "To find these objects, we'll loop through each satellite and throw out any that do not have main trees going beyond redshift $z=3$. This will update to an array called `nstree_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#throw out orphan subhalos\n",
    "nstree_id=[]\n",
    "for tid in nstree_id_:\n",
    "    w=np.where(tid==tree_ids)[0]; z=redshift[w]\n",
    "    if(z[-1]>3):\n",
    "        nstree_id.append(tid)\n",
    "    else:\n",
    "        pass\n",
    "nstree_id=np.array(nstree_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll do the whole loop for each satellite, but I'll leave it up to you how you want to save each and every dataset. I'll save each halo with the tree id to a dictionary called `sat_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo=Cosmology(**params)\n",
    "dyn=Dynamics(**params)\n",
    "\n",
    "sat_data={} # contains the entire satellite tree data\n",
    "ftree_id=[] # corrected satellite IDs\n",
    "for tid in nstree_id[:]:\n",
    "    sat_tree={}\n",
    "    \n",
    "    #partition out satellite quantities baed on tree depth\n",
    "    ws=np.where(tid==tree_ids)[0];\n",
    "    sat_tree['virial.mass']=tmvir[ws]\n",
    "    sat_tree['scale']=scale[ws]; sat_tree['redshift']=redshift[ws]\n",
    "    sat_tree['vel.max']=tvmax[ws] # physical kpc\n",
    "    sat_tree['rad.max']=sat_tree['scale']*trmax[ws] # physical kpc\n",
    "    \n",
    "    sat_tree['position']=np.zeros((sat_tree['scale'].shape[0],3)) # physical kpc\n",
    "    sat_tree['position'][:,0]=sat_tree['scale']*xpos[ws]*1e3/h0\n",
    "    sat_tree['position'][:,1]=sat_tree['scale']*ypos[ws]*1e3/h0\n",
    "    sat_tree['position'][:,2]=sat_tree['scale']*zpos[ws]*1e3/h0\n",
    "    \n",
    "    sat_tree['velocity']=np.zeros((sat_tree['scale'].shape[0],3)) # peculiar km/s\n",
    "    sat_tree['velocity'][:,0]=xvel[ws]; sat_tree['velocity'][:,1]=yvel[ws]; sat_tree['velocity'][:,2]=zvel[ws]\n",
    "\n",
    "    '''Sometimes the satellite halos will have missing tree data at higher redshifts compared to MW, \n",
    "    which we expect to 'complete'. Below is a routine to make sure the host halo data and the satellite data \n",
    "    match at each snapshot/redshift.'''\n",
    "    \n",
    "    #partition out matching redshift host halo quantities\n",
    "    wh=np.where(np.in1d(host_tree['scale'],sat_tree['scale']))[0]\n",
    "    if(wh.shape[0]!=sat_tree['scale'].shape[0]):\n",
    "        # I was too lazy to correct this...\n",
    "        pass\n",
    "    else:\n",
    "        ftree_id.append(int(tid))\n",
    "        sat_data[str(int(tid))]=sat_tree\n",
    "            \n",
    "        # matched snapshot host values\n",
    "        # use these when doing dynamical analysis\n",
    "        sat_tree['distance']=dyn.distance(sat_tree['redshift'],\n",
    "                                          host_tree['position'][wh],sat_tree['position'])['relative.distance:magnitude']\n",
    "        sat_tree['distance:pericenter']=min(sat_tree['distance'])\n",
    "        \n",
    "        sat_tree['total.velocity']=dyn.total_velocity(sat_tree['redshift'],host_tree['velocity'][wh],sat_tree['velocity'],host_tree['position'][wh],sat_tree['position'])['total.velocity:magnitude']\n",
    "        sat_tree['radial.velocity']=dyn.radial_velocity(sat_tree['redshift'],host_tree['velocity'][wh],sat_tree['velocity'],host_tree['position'][wh],sat_tree['position'])\n",
    "        sat_tree['tangential.velocity']=dyn.tangential_velocity(sat_tree['redshift'],host_tree['velocity'][wh],sat_tree['velocity'],host_tree['position'][wh],sat_tree['position'])\n",
    "        sat_tree['space.velocity']=dyn.space_velocity(sat_tree['redshift'],host_tree['velocity'][wh],sat_tree['velocity'],host_tree['position'][wh],sat_tree['position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[116.70413868 116.94377791 115.6545454  108.09440424  97.93867081\n",
      "  94.0932472  101.7932344  109.57140021 110.08992235 103.05019895\n",
      "  88.95259797  36.15744269  37.65630867  48.59170508  61.80393139\n",
      "  75.11393642  85.73744346  95.37390869 104.28609225 110.02703714\n",
      "  92.15296256 118.63315353 120.89386739 121.66118483 120.36996121\n",
      " 117.32863248 112.70484102 105.39338885  96.67369544  86.66733465\n",
      "  74.28887292  61.51001424  49.78684759  43.45520491  52.3090255\n",
      "  58.03255239  67.93085066  77.85073225  86.74999344  94.28693437\n",
      " 100.39769548 105.07546441 108.76040766 111.4495865  113.31611128\n",
      " 114.44691042 115.34506403 116.62242268 117.47419782 116.00019957\n",
      " 112.01491028 106.43708567  99.46383063  91.06730645  81.7124946\n",
      "  71.89294866  62.45089233  55.61805174  54.8665906   61.78631087\n",
      "  72.54713144  83.57351403  93.84467018 103.87939714 113.63790878\n",
      " 123.52888733 132.9871353  141.93637628 152.53188823 164.66092754\n",
      " 177.65539181 190.82791196 203.6144766  215.45027882 225.80849646\n",
      " 234.6780008  238.53456213 245.52495937 251.824992   257.21699989\n",
      " 262.13082063 267.02324374 271.83116081 276.68404194 281.74175272\n",
      " 286.45145146 290.3578225  293.28569294 295.59810891 296.90405798\n",
      " 297.76562354 299.16142249 300.94472079 302.73475064 304.28609693\n",
      " 305.98686294 308.2097844  309.41286117 312.49864059 315.87707313\n",
      " 318.89904094 322.64724938 325.94986669 330.71478529 334.9432543\n",
      " 338.53143432 339.91152008 338.11699778 337.58323976 338.25386435\n",
      " 338.88327349 339.0078528  338.81542632 338.05600318 337.36623528\n",
      " 336.53168391 332.73698745 328.71565534 324.64315841 320.63426902\n",
      " 316.66809046 311.17217313 305.6381467  303.22854774 300.36809782\n",
      " 296.97182089 292.83646059 288.75626866 283.15337013 275.88174549\n",
      " 268.26858495 260.75195496 252.73359255 243.43065122 233.39338066\n",
      " 224.216307   212.53447039 201.16913262 190.98526338 180.6960101\n",
      " 169.5686378  157.7112675  144.97536746 131.84536195]\n"
     ]
    }
   ],
   "source": [
    "print(sat_data['25258073']['distance'])\n",
    "#print(sat_data['25258073']['radial.velocity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
